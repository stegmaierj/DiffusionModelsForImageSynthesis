{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f58caaa",
   "metadata": {},
   "source": [
    "# Application Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be99b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import ipywidgets as wg\n",
    "from IPython.display import display, Javascript \n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "from utils.jupyter_widgets import get_pipelin_widget, get_apply_parameter_widgets, get_execution_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a674686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('The following GPU was found:\\n')\n",
    "    print('CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "else:\n",
    "    print('No GPU was found. CPU will be used.')\n",
    "\n",
    "# Select a pipeline \n",
    "pipeline = get_pipelin_widget()\n",
    "display(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162637c",
   "metadata": {},
   "source": [
    "---\n",
    "After executing the next block, please adapt all parameters accordingly.\n",
    "The pipeline expects a list of files that should be used for testing. \n",
    "Absolute paths to each files are automatically obtained by concatenating the provided data root and each entry of the file lists. When changing the selected pipeline, please again execute the following block.<br>\n",
    "A pretrained model is already provided with the repository for demonstration purposes. Further pretrained models can be downloaded from https://transfer.lfb.rwth-aachen.de/CellDiffusion/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22365964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define general inference parameters\n",
    "params = {'output_path': '../data_samples/experiment_3D',\n",
    "          'ckpt_path': '../data_samples/experiment_3D/Diffusion_3DCTC_CE_epoch=4999.ckpt',\n",
    "          'gpus': use_cuda,\n",
    "          'overlap': (0,20,20),\n",
    "          'crop': (0,20,20),\n",
    "          'input_batch': 'image',\n",
    "          'clip': (-1.0, 1.0),\n",
    "          'num_files':-1,\n",
    "          'add_noise_channel': False,\n",
    "          'pipeline': pipeline.value,\n",
    "          }\n",
    "\n",
    "params_diff = {'timesteps_start': 400,\n",
    "               'timesteps_save': 100,\n",
    "               'timesteps_step': 1,\n",
    "               'blur_sigma': 1\n",
    "              }\n",
    "\n",
    "\n",
    "# Load selected pipeline\n",
    "if  params['pipeline'].lower() == 'diffusionmodel3d':\n",
    "    from models.DiffusionModel3D import DiffusionModel3D as network\n",
    "    params.update(params_diff)\n",
    "elif params['pipeline'].lower() == 'diffusionmodel2d':\n",
    "    from models.DiffusionModel2D import DiffusionModel2D as network\n",
    "    params.update(params_diff)\n",
    "else:\n",
    "    raise ValueError('Pipeline {0} unknown.'.format(params['pipeline']))\n",
    "\n",
    "    \n",
    "# Get and show corresponding parameters\n",
    "pipeline_args = ArgumentParser(add_help=False)\n",
    "pipeline_args = network.add_model_specific_args(pipeline_args)\n",
    "pipeline_args = vars(pipeline_args.parse_known_args()[0])\n",
    "params = {**params, **pipeline_args}\n",
    "\n",
    "print('-'*60+'\\nPARAMETER FOR PIPELINE \"{0}\"\\n'.format(pipeline.value)+'-'*60)\n",
    "param_names, widget_list = get_apply_parameter_widgets(params)\n",
    "for widget in widget_list: \n",
    "    display(widget)\n",
    "    \n",
    "print('-'*60+'\\nEXECUTION SETTINGS\\n'+'-'*60)\n",
    "wg_execute, wg_arguments = get_execution_widgets()\n",
    "display(wg_arguments)\n",
    "display(wg_execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19adcedb",
   "metadata": {},
   "source": [
    "---\n",
    "Finish preparations and start processing by executing the next block. The outputs are expected to be in the value range (-1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec280ea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "param_names = [p for p,w in zip(param_names, widget_list) if w.value!=False and w.value!='']\n",
    "widget_list = [w for w in widget_list if w.value!=False and w.value!='']\n",
    "command_line_args = ' '.join(['--pipeline {0}'.format(pipeline.value)]+\\\n",
    "                             [n+' '+str(w.value) if not type(w.value)==bool else n\\\n",
    "                              for n,w in zip(param_names, widget_list)])\n",
    "\n",
    "# Show the command line arguments\n",
    "if wg_arguments.value:\n",
    "    print('_'*90+'\\nCOMMAND LINE ARGUMENTS FOR apply_script_diffusion.py WITH PIPELINE \"{0}\"\\n'.format(pipeline.value)+'-'*90)\n",
    "    print(command_line_args)\n",
    "    print('\\n')\n",
    "        \n",
    "# Execute the pipeline\n",
    "if wg_execute.value:\n",
    "    print('_'*60+'\\nEXECUTING PIPELINE \"{0}\"\\n'.format(pipeline.value)+'-'*60)\n",
    "    %run \"../apply_script_diffusion.py\" {command_line_args}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3d6afa663d3b7d8b7c28e0e5bf1fc62360d26f74485b03653b2cb99921ca431b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
